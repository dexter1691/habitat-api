{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/coc/pskynet3/hagrawal9/project/habitat/habitat-api\n"
     ]
    }
   ],
   "source": [
    "cd '/srv/share3/hagrawal9/project/habitat/habitat-api/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from typing import Any, Dict, List, Optional, Type\n",
    "from copy import deepcopy\n",
    "\n",
    "import attr\n",
    "import cv2\n",
    "import git\n",
    "import magnum as mn\n",
    "import numpy as np\n",
    "\n",
    "# %matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import habitat\n",
    "import habitat_sim\n",
    "from habitat.config import Config\n",
    "from habitat.core.registry import registry\n",
    "from habitat_sim.utils import viz_utils as vut\n",
    "from habitat.utils.visualizations import maps, fog_of_war\n",
    "from habitat.utils.visualizations.utils import observations_to_image\n",
    "\n",
    "from rearrangement.utils.planner import (\n",
    "    compute_traversable_map,\n",
    "    compute_distance_using_fmm,\n",
    "    find_dist_from_map,\n",
    "    compute_distance_mat_using_navmesh,\n",
    "    compute_distance_mat_using_fmm,\n",
    "    find_shortest_path_for_multiple_objects\n",
    ")\n",
    "from rearrangement.utils.visualization import (\n",
    "    get_top_down_map\n",
    ")\n",
    "from rearrangement.utils.geometry import (\n",
    "     geodesic_distance\n",
    ")\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from habitat.datasets.rearrangement.rearrangement_dataset import RearrangementDatasetV0\n",
    "from habitat.tasks.rearrangement.rearrangement_task import RearrangementEpisode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = git.Repo(\".\", search_parent_directories=True)\n",
    "dir_path = repo.working_tree_dir\n",
    "# %cd $dir_path\n",
    "data_path = os.path.join(dir_path, \"data\")\n",
    "output_directory = \"data/tutorials/output/\"  # @param {type:\"string\"}\n",
    "output_path = os.path.join(dir_path, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = habitat.get_config(\"configs/tasks/rearrangement_gibson.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.defrost()\n",
    "config.TASK.MEASUREMENTS = ['OBJECT_TO_GOAL_DISTANCE', 'AGENT_TO_OBJECT_DISTANCE', 'TOP_DOWN_MAP']\n",
    "config.DATASET.SPLIT = \"val\"\n",
    "config.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config({'TYPE': 'RearrangementDataset-v0', 'SPLIT': 'val', 'SCENES_DIR': 'data/scene_datasets', 'CONTENT_SCENES': ['*'], 'DATA_PATH': 'data/datasets/rearrangement/gibson/v1/{split}/{split}.json.gz'})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TASK.TOP_DOWN_MAP.MAP_RESOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-27 11:40:42,840 Initializing dataset RearrangementDataset-v0\n",
      "2020-10-27 11:40:43,126 initializing sim RearrangementSim-v0\n",
      "I1027 11:40:48.643167 33504 simulator.py:168] Loaded navmesh data/scene_datasets/gibson_train_val/Hallettsville.navmesh\n",
      "I1027 11:40:48.644935 33504 simulator.py:180] Recomputing navmesh for agent's height 0.88 and radius 0.18.\n",
      "2020-10-27 11:40:48,921 Initializing task RearrangementTask-v0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n",
    "env = habitat.Env(config)\n",
    "fog_of_war_mask = None\n",
    "pickup_order = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env.episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-11.284797668457031, 0.17394161224365234, -5.5449724197387695]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.current_episode.start_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_env_episode_distance(env, pickup_order):\n",
    "    \n",
    "    traversal_order = []\n",
    "    pathfinder = env._task._simple_pathfinder\n",
    "    episode = env.current_episode \n",
    "    # dist_mat = compute_distance_mat_using_navmesh(env._task._simple_pathfinder, agent_pos, object_positions, goal_positions)\n",
    "    \n",
    "    agent_pos = env._sim.get_agent(0).get_state().position\n",
    "    object_positions = [obj.position for obj in episode.objects]\n",
    "    goal_positions = [obj.position for obj in episode.goals]\n",
    "    \n",
    "    prev_obj_end_pos = agent_pos\n",
    "    shortest_dist = 0\n",
    "\n",
    "    for i in range(len(pickup_order)):\n",
    "        curr_idx = pickup_order[i] - 1\n",
    "        curr_obj_start_pos = object_positions[curr_idx]\n",
    "        curr_obj_end_pos = goal_positions[curr_idx]\n",
    "        shortest_dist += geodesic_distance(\n",
    "                pathfinder, prev_obj_end_pos, [curr_obj_start_pos]\n",
    "            )\n",
    "\n",
    "        shortest_dist += geodesic_distance(\n",
    "                    pathfinder, curr_obj_start_pos, [curr_obj_end_pos]\n",
    "                ) \n",
    "        prev_obj_end_pos = curr_obj_end_pos\n",
    "        \n",
    "        \n",
    "    return {\n",
    "        'episode_id': episode.episode_id, \n",
    "        'scene_id': episode.scene_id,\n",
    "        'episode_dist': shortest_dist\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.98417782783508 (1, 2)\n",
      "39.98417782783508 [1, 2]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "all_permutations = list(itertools.permutations(range(1, len(env.current_episode.objects) + 1)))\n",
    "min_dist = 1000\n",
    "for pickup_order in all_permutations:\n",
    "    is_oracle = False\n",
    "    d = start_env_episode_distance(env, pickup_order)\n",
    "    if list(pickup_order) == list(env.current_episode.pickup_order):\n",
    "        is_oracle = True\n",
    "        oracle_dist = d['episode_dist']\n",
    "    if d['episode_dist'] < min_dist:\n",
    "        min_dist = d['episode_dist']\n",
    "        min_order = pickup_order\n",
    "        \n",
    "    # print(\"Oracle: {}\".format(is_oracle), pickup_order, d['episode_dist'])\n",
    "if min_dist < oracle_dist:\n",
    "    print(\"found shorter path\")\n",
    "\n",
    "print(min_dist, min_order)\n",
    "print(oracle_dist, env.current_episode.pickup_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPL(Measure):\n",
    "    r\"\"\"SPL (Success weighted by Path Length)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, sim, config: Config, *args: Any, **kwargs: Any\n",
    "    ):\n",
    "        self._previous_position = None\n",
    "        self._start_end_episode_distance = None\n",
    "        self._agent_episode_distance = None\n",
    "        self._episode_view_points = None\n",
    "        self._sim = sim\n",
    "        self._config = config\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def _get_uuid(self, *args: Any, **kwargs: Any) -> str:\n",
    "        return \"spl\"\n",
    "\n",
    "    def reset_metric(self, episode, task, *args: Any, **kwargs: Any):\n",
    "        task.measurements.check_measure_dependencies(\n",
    "            self.uuid, [DistanceToGoal.cls_uuid, Success.cls_uuid]\n",
    "        )\n",
    "\n",
    "        self._previous_position = self._sim.get_agent_state().position\n",
    "        self._agent_episode_distance = 0.0\n",
    "        self._start_end_episode_distance = task.measurements.measures[\n",
    "            DistanceToGoal.cls_uuid\n",
    "        ].get_metric()\n",
    "        self.update_metric(episode=episode, task=task, *args, **kwargs)\n",
    "\n",
    "    def _euclidean_distance(self, position_a, position_b):\n",
    "        return np.linalg.norm(position_b - position_a, ord=2)\n",
    "\n",
    "    def update_metric(\n",
    "        self, episode, task: EmbodiedTask, *args: Any, **kwargs: Any\n",
    "    ):\n",
    "        ep_success = task.measurements.measures[Success.cls_uuid].get_metric()\n",
    "\n",
    "        current_position = self._sim.get_agent_state().position\n",
    "        self._agent_episode_distance += self._euclidean_distance(\n",
    "            current_position, self._previous_position\n",
    "        )\n",
    "\n",
    "        self._previous_position = current_position\n",
    "\n",
    "        self._metric = ep_success * (\n",
    "            self._start_end_episode_distance\n",
    "            / max(\n",
    "                self._start_end_episode_distance, self._agent_episode_distance\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scratch Code\n",
    "# for objid in env._sim.get_existing_object_ids():\n",
    "#     if objid != env._sim.agent_object_id:\n",
    "#         episode_obj_id = env._task.sim_object_to_objid_mapping[objid]\n",
    "#         dist = geodesic_distance(env._sim.pathfinder, agent_pos, env.current_episode.objects[episode_obj_id].position)\n",
    "#         if dist == np.inf:\n",
    "#             print(\"Voila!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env.episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode ID: 19 Done: 1000  "
     ]
    }
   ],
   "source": [
    "while(len(pickup_order)!=len(env.episodes)):\n",
    "    data = compute_l2dist_pickup_order(env)\n",
    "    pickup_order[data['episode_id'] + '_' + data['scene_id']] = data\n",
    "    print('\\rEpisode ID: {} Done: {} '.format(data['episode_id'], len(pickup_order)), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pickup_order_l2dist_test.json','w') as f:\n",
    "    json.dump(pickup_order, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pickup_order_l2dist_train.json','r') as f:\n",
    "    pickup_order_l2dist = json.load(f)\n",
    "    \n",
    "with open('data/pickup_order_tdmap_train.json','r') as f:\n",
    "    pickup_order_tdmap = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rearrangement_v1_train_n=1000_o=5_Monson.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Scandinavia.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Hobson.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Barboursville.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Mentasta.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Avonia.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Ewell.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Gilbert.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Sawpit.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Montreal.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Orason.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Hainesburg.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Helix.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Westerville.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Arona.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Delton.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Roeville.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Euharlee.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Hominy.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Bowlus.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Rancocas.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Seatonville.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Stilwell.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Roxboro.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Hercules.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Whitethorn.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Wesley.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Fredericksburg.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Stanleyville.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Grantsville.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Ovalo.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Trail.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Barranquitas.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Cutlerville.json.gz\n",
      "rearrangement_v1_train_n=1000_o=5_Shelbiana.json.gz\n"
     ]
    }
   ],
   "source": [
    "updated_scene_data = []\n",
    "split = 'train'\n",
    "\n",
    "for filename in os.listdir('data/datasets/rearrangement/gibson/v1/{}/content/'.format(split)):\n",
    "    scene_id = filename.split('.')[0].split('_')[-1]\n",
    "    with gzip.open('data/datasets/rearrangement/gibson/v1/{}/content/'.format(split) + filename, \"rt\") as f:\n",
    "        scene_data = json.load(f)\n",
    "    updated_scene_data = deepcopy(scene_data)\n",
    "    \n",
    "    for i, episode in enumerate(scene_data['episodes']):\n",
    "        episode_id = episode['episode_id']\n",
    "        assert updated_scene_data['episodes'][i]['episode_id'] == episode['episode_id']\n",
    "        assert updated_scene_data['episodes'][i]['scene_id'] == episode['scene_id']\n",
    "        updated_scene_data['episodes'][i]['pickup_order_tdmap'] = pickup_order_tdmap[str(episode['episode_id']) + \"_\" + episode['scene_id']]['pickup_order_fmm']\n",
    "        updated_scene_data['episodes'][i]['pickup_order_l2dist'] = pickup_order_l2dist[str(episode['episode_id']) + \"_\" + episode['scene_id']]['pickup_order_l2dist']\n",
    "    \n",
    "    \n",
    "    with gzip.open('data/datasets/rearrangement/gibson/v1/{}/content/'.format(split) + filename, \"wt\") as f:\n",
    "        json.dump(updated_scene_data, f)\n",
    "        \n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
