{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tel = torch.nn.TransformerEncoderLayer(64, 4, 512, dropout=0.0, activation='relu')\n",
    "te = torch.nn.TransformerEncoder(tel, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.randn((5, 12, 64))\n",
    "src_mask = torch.zeros((12, 5), dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_mask.to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = te(s, src_key_padding_mask=src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 12, 64])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 64])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(o, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       ".. function:: mean(input) -> Tensor\n",
       "\n",
       "Returns the mean value of all elements in the :attr:`input` tensor.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the input tensor.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.randn(1, 3)\n",
       "    >>> a\n",
       "    tensor([[ 0.2294, -0.5481,  1.3288]])\n",
       "    >>> torch.mean(a)\n",
       "    tensor(0.3367)\n",
       "\n",
       ".. function:: mean(input, dim, keepdim=False, out=None) -> Tensor\n",
       "\n",
       "Returns the mean value of each row of the :attr:`input` tensor in the given\n",
       "dimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\n",
       "reduce over all of them.\n",
       "\n",
       "\n",
       "If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
       "as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
       "Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
       "output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
       "\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the input tensor.\n",
       "    dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
       "    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
       "    out (Tensor, optional): the output tensor.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.randn(4, 4)\n",
       "    >>> a\n",
       "    tensor([[-0.3841,  0.6320,  0.4254, -0.7384],\n",
       "            [-0.9644,  1.0131, -0.6549, -1.4279],\n",
       "            [-0.2951, -1.3350, -0.7694,  0.5600],\n",
       "            [ 1.0842, -0.9580,  0.3623,  0.2343]])\n",
       "    >>> torch.mean(a, 1)\n",
       "    tensor([-0.0163, -0.5085, -0.4599,  0.1807])\n",
       "    >>> torch.mean(a, 1, True)\n",
       "    tensor([[-0.0163],\n",
       "            [-0.5085],\n",
       "            [-0.4599],\n",
       "            [ 0.1807]])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
